---
title: "Age Concepts"
author:
  - name: ""
    affiliation: ""
    corresponding: yes
    address: ""
    email: ""

keywords          : "keywords"
wordcount         : "X"

floatsintext      : no
linenumbers       : yes
draft             : no
mask              : no

figurelist        : no
tablelist         : no
footnotelist      : no

classoption       : "man"
output            : papaja::apa6_word
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(fig.width=8, fig.height=5, 
               echo=FALSE, 
               warning=FALSE, message=FALSE, 
               cache=TRUE)
```

```{r}
library('performance')
library('devtools')
library('tidyverse')
library("purrr")
library('ggplot2')
library('lme4')
library('car')
library('emmeans')
library('prmisc')
library('report')
library('readxl')
library('dplyr')
library('papaja')
library('AICcmodavg')
```

```{r, analysis-preferences}
# Seed for random number generation
set.seed(32)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)

force_decimals <- function(x, digits = 2) {
  formatC(x, format = "f", digits = digits)
}

print_coeff <- function(model, factor, factor_label = "") {
  coef = force_decimals(coef(summary(model))[factor, "Estimate"])
  ci1 = force_decimals(confint.merMod(model,method="Wald")[factor, '2.5 %'])
  ci2 = force_decimals(confint.merMod(model,method="Wald")[factor, '97.5 %'])
  p = format_p(coef(summary(model))[factor, "Pr(>|z|)"])
  return(paste("$\\beta$", factor_label, " = ", coef, ", ", 
      "95% CI = [", ci1, ", ", ci2, "], ", 
      p, sep = ""))
}

print_coeff_p <- function(model, factor, factor_label = "") {
  return(format_p(coef(summary(model))[factor, "Pr(>|z|)"]))
}

print_model_comp <- function(model_comp, factor) {
  df = model_comp[factor, "Df"]
  chi = force_decimals(model_comp[factor, "Chisq"])
  p = format_p(model_comp[factor, "Pr(>Chisq)"])
  return(paste("$\\chi^2$(", 
               df, ") = ", 
               chi, ", ", 
               p, sep = ""))
}

print_model_comp_p <- function(model_comp, factor) {
  return(format_p(model_comp[factor, "Pr(>Chisq)"]))
}

# print out aic and bic
print_model_fit <- function(model1, model2) {
  aic <- aictab(cand.set = list(model1, model2), sort = F) %>%
    pull(Delta_AICc)
  delta_aic <- force_decimals(aic[1] - aic[2])
  bic <- bictab(cand.set = list(model1, model2), sort = F) %>%
    pull(Delta_BIC)
  delta_bic <- force_decimals(bic[1] - bic[2])
  return(paste("$\\Delta AICc$ = ", 
               delta_aic, ", $\\Delta BIC$ = ", 
               delta_bic, sep = ""))
}

print_emm_contrast <- function(contrast_df, contrast_label, filter_level = NULL, digits = 2) {
  if (!is.null(filter_level)) {
    contrast_df <- contrast_df %>%
      filter(grepl(filter_level, as.character(contrast_df$contrast), fixed = TRUE) |
             grepl(filter_level, as.character(contrast_df$Congruence), fixed = TRUE))
  }
  row <- contrast_df %>%
    filter(contrast == contrast_label)

  if (nrow(row) == 0) {
    return("N/A")
  }

  with(row, sprintf("Odds ratio = %.2f, SE = %.2f, z = %.2f, p = %s",
                    odds.ratio, SE, z.ratio,
                    ifelse(p.value < .001, "< .001", paste0("= ", round(p.value, digits)))))
}
```

```{r, get data, add age group}
df <- read.csv("~/AgeConcepts/Age-Concepts/Age-Concepts-Data.csv")
df <- df %>%
  mutate(AgeGroup = case_when(
    Age >= 3 & Age < 4   ~ '3',
    Age >= 4 & Age < 5   ~ '4',
    Age >= 5 & Age < 6   ~ '5'
  ))
df_clean <- df %>%
  filter(Task == 'AJT')
```

```{r, data entry checks}
length(unique(df_clean$PID))
all(table(df_clean$PID) == 18)
df_clean$Condition <- trimws(df_clean$Condition)
df_clean %>%
  group_by(AgeGroup, Condition) %>%
  summarise(
    n_unique_PID = n_distinct(PID),
    mean_age = mean(Age, na.rm = TRUE),
    .groups = "drop"
  )
df_clean %>%
  group_by(Condition) %>%
  summarise(mean_age = mean(Age, na.rm = TRUE))
```

```{r, transforming data}
df_clean$AJT_Accuracy <- as.numeric(df_clean$AJT_Accuracy)
df_clean$Age_scaled <- scale(df_clean$Age)
```

```{r, base model}
glmer1 <- glmer(AJT_Accuracy ~ Age_scaled + (1|PID) + (1|Item), data = df_clean, family = 'binomial', control = glmerControl(optimizer = "bobyqa"))
Anova(glmer1)
```

```{r, base model with identical random effect structure as following model for comparison}
glmer1_forcomparison <- glmer(AJT_Accuracy ~ Age_scaled + (1+ Congruence|PID) + (1|Item), data = df_clean, family = 'binomial', control = glmerControl(optimizer = "bobyqa"))
```

```{r, augmented model with Congruence added}
glmer2 <- glmer(AJT_Accuracy ~ Age_scaled + Congruence + (1 + Congruence|PID) + (1|Item), data = df_clean, family = 'binomial', control = glmerControl(optimizer = "bobyqa"))
model_comp_congruence <- anova(glmer1_forcomparison, glmer2)
model_comp_congruence
```


```{r, exploring effect of congruence}
glmer2.congruence <- glmer2 %>% 
  emmeans(specs = pairwise ~ Congruence,
          type = "response",
          adjust = "bonferroni") %>%
  pluck("contrasts") %>%
  summary()
glmer2.congruence
```


```{r, glmer2 with identical random effect structure as following model for comparison}
glmer2_forcomparison <- glmer(AJT_Accuracy ~ Age_scaled + Congruence + (1 + Congruence|PID) + (1 + Condition|Item), data = df_clean, family = 'binomial',  control = glmerControl(optimizer = "bobyqa"))
```
```{r, augmented model with Numerical Age Condition term added}
glmer3 <- glmer(AJT_Accuracy ~ Age_scaled + Congruence + Condition + (1 + Congruence|PID) + (1 + Condition|Item), data = df_clean, family = 'binomial',  control = glmerControl(optimizer = "bobyqa"))
model_comp_condition <- anova(glmer2_forcomparison, glmer3)
```

```{r, exploring the effect of condition}
glmer3.condition <- glmer3 %>% 
  emmeans(specs = pairwise ~ Condition,
          type = "response",
          adjust = "bonferroni") %>%
  pluck("contrasts") %>%
  summary()
glmer3.condition
```


```{r, augmented model with Later Greater accuracy term added}
glmer4 <- glmer(AJT_Accuracy ~ Age_scaled + Congruence + Condition + LG_Accuracy + (1 + Congruence|PID) + (1 + Condition|Item), data = df_clean, family = 'binomial',  control = glmerControl(optimizer = "bobyqa"))
model_comp_LG <- anova(glmer3, glmer4)
```

```{r, augmented model with Autobiographical Memory accuracy term added}
glmer5 <- glmer(AJT_Accuracy ~ Age_scaled + Congruence + Condition + LG_Accuracy + AMT_Accuracy + (1 + Congruence|PID) + (1 + Condition|Item), data = df_clean, family = 'binomial',  control = glmerControl(optimizer = "bobyqa"))
model_comp_AMT <- anova(glmer4, glmer5)
```


```{r, exploration of whether to model LG Accuracy differently}
df_summary <- df_clean %>%
  group_by(PID) %>%
  summarise(
    LG_Accuracy = mean(LG_Accuracy),
    AJT_Accuracy = mean(AJT_Accuracy)
  ) %>%
  mutate(LG_Score = LG_Accuracy * 6)

df_grouped <- df_summary %>%
  group_by(LG_Score) %>%
  summarise(
    Mean_AJT = mean(AJT_Accuracy),
    n = n()
  )

# ggplot(df_grouped, aes(x = as.factor(LG_Score), y = Mean_AJT)) +
 # geom_col(fill = "steelblue") +
 # geom_text(aes(label = paste0("n = ", n)), vjust = -0.5) +
 # labs(
 #   x = "Number Correct on LG Task (0â€“6)",
 #   y = "Mean AJT Accuracy",
 #   title = "AJT Accuracy by LG Task Score"
 # ) +
  #theme_minimal()
```

```{r}
df_clean <- df_clean %>%
  group_by(PID) %>%
  mutate(LG_Accuracy_Binary = ifelse(any(LG_Accuracy == 0), 0, 1)) %>%
  ungroup()

ajt_summary <- df_clean %>%
  group_by(PID, LG_Accuracy_Binary) %>%
  summarise(AJT_Accuracy = mean(AJT_Accuracy), .groups = "drop")

# t.test(AJT_Accuracy ~ LG_Accuracy_Binary, data = ajt_summary)
```

```{r, exploration of whether to model LG Accuracy as binary}
glmer4_LGbinary <- glmer(AJT_Accuracy ~ Age_scaled + Congruence + Condition + LG_Accuracy_Binary + (1 + Congruence|PID) + (1 + Condition|Item), data = df_clean, family = 'binomial',  control = glmerControl(optimizer = "bobyqa"))
model_comp_LGbinary <- anova(glmer3, glmer4_LGbinary)
```


```{r, exploration of whether to model LG Accuracy as continuous}
df_clean <- df_clean %>%
  group_by(PID) %>%
  mutate(LG_Accuracy_Continuous = sum(LG_Accuracy) / 3) %>%
  ungroup()

glmer4_LGContinuous <- glmer(AJT_Accuracy ~ Age_scaled + Congruence + Condition + LG_Accuracy_Continuous + (1 + Congruence|PID) + (1 + Condition|Item), data = df_clean, family = 'binomial',  control = glmerControl(optimizer = "bobyqa"))
model_comp_LGcontinuous <- anova(glmer3, glmer4_LGContinuous)
```

```{r, interaction between congruence and condition}
int_model_congruence_condition <- glmer(AJT_Accuracy ~ Condition * Congruence + (1|PID) + (1|Item), data = df_clean, family = 'binomial', control = glmerControl(optimizer = "bobyqa"))
comp_model_congruence_condition <- glmer(AJT_Accuracy ~ Condition + Congruence + (1|PID) + (1|Item), data = df_clean, family = 'binomial', control = glmerControl(optimizer = "bobyqa"))
model_comp_int_congruence_condition <- anova(int_model_congruence_condition, comp_model_congruence_condition)
model_comp_int_congruence_condition
```
```{r, exploration of the interaction between congruence and condition}
congruence_condition_int <- int_model_congruence_condition %>% 
  emmeans(specs = pairwise ~ Condition | Congruence,
          type = "response",
          adjust = "bonferroni") %>%
  pluck("contrasts") %>%
  summary()
congruence_condition_int
```



```{r}
int_model <- glmer(AJT_Accuracy ~ Condition * LG_Accuracy + (1|PID) + (1|Item), data = df_clean, family = 'binomial', control = glmerControl(optimizer = "bobyqa"))
Anova(int_model)
comp_model <- glmer(AJT_Accuracy ~ Condition + LG_Accuracy + (1|PID) + (1|Item), data = df_clean, family = 'binomial', control = glmerControl(optimizer = "bobyqa"))
anova(int_model, comp_model)
```


```{r}
int_model_continuous <- glmer(AJT_Accuracy ~ Condition * LG_Accuracy_Continuous + (1|PID) + (1|Item), data = df_clean, family = 'binomial', control = glmerControl(optimizer = "bobyqa"))
Anova(int_model_continuous)
comp_model_continuous <- glmer(AJT_Accuracy ~ Condition + LG_Accuracy_Continuous + (1|PID) + (1|Item), data = df_clean, family = 'binomial', control = glmerControl(optimizer = "bobyqa"))
anova(int_model_continuous, comp_model_continuous)
```

Our primary aim of this study was to better understand children's development of the concept of age and which factors contribute to this development. To do so, we analyzed children's performance in the Age Judgment Task and examined its relation to several elements in the task structure and children's performance on the two other tasks in the study, the Later-Greater Task and the Autobiographical Memory Task. Our primary analyses were based on a pre-registered plan available through OSF, which we supplemented with several exploratory and post-hoc analyses. Model comparisons were performed using likelihood ratio tests and the best-fitting models were selected on the basis of a significant chi-square statistic and reduced AIC value. All post hoc pairwise comparisons were adjusted for multiple comparisons using a Bonferroni correction.

To test which factors influence children's understanding of age, we constructed several generalized linear mixed models predicting children's accuracy on the Age Judgment Task using the lme4 (Bates et al., 2015) R package. Our base model included only age (months) as a fixed effect, with participant and item as random effects. This model revealed that children's performance in the Age Judgment Task improved with age, `r print_coeff(glmer1, "Age_scaled")`. To assess the impact of size on children's age judgments, we added a term for congruence (congruent/incongruent/same size) to our model. Relative to the simpler model with only age as a fixed factor, this augmented model significantly improved fit to the data (`r print_model_comp(model_comp_congruence, "glmer2")`), suggesting that children are influenced by size when making age judgments. Posthoc pairwise comparisons using the emmeans (Lenth, 2024) R Package showed that children were more accurate in the congruent condition than in both the same size (`r print_emm_contrast(glmer2.congruence, "Congruent / Same")`) and incongruent conditions (`r print_emm_contrast(glmer2.congruence, "Congruent / Incongruent")`), and also performed better in the same size condition than in the incongruent condition (`r print_emm_contrast(glmer2.congruence, "Incongruent / Same")`). Next, to assess whether having access to the numerical ages of the figures in the Age Judgment Task influenced children's performance, we added a term for numerical age condition (age provided/age not provided) to our model. This augmented model significantly improved fit to the data (`r print_model_comp(model_comp_condition, "glmer3")`), suggesting that accessing numerical age influences children's age judgments. Posthoc pairwise comparisons showed that children were more accurate when they had access to the numerical ages than when they did not (`r print_emm_contrast(glmer3.condition, "Age / No Age")`). Adding a term for accuracy on the Later-Greater Task on the trial with the same pair of numbers as the ages the figures on that trial of the Age Judgment Task were meant to represent did not significantly improve model fit (`r print_model_comp(model_comp_LG, "glmer4")`). This suggests that knowledge of which of the numbers is greater on a trial of the Age Judgment Task may not allow children to make more accurate age judgments, but there are multiple reasons to doubt this conclusion. First, knowledge of which number is greater would not have been of use for participants in the condition of the Age Judmgent Task in which numerical ages were not provided. Furthermore, participants only completed one trial in the Later-Greater Task for each pair of numbers, rendering the reliability of their accuracy for that pair of numbers low. Because of these concerns, we constructed an exploratory model which added a term for accuracy on the Later-Greater Task as a total score rather than by trial. This model did significantly improve fit to the data (`r print_model_comp(model_comp_LGcontinuous, "glmer4_LGContinuous")`), suggesting that more generally, greater numerical knowledge may lead children to a more accurate concept of age and ability to make relative age judgments. Finally, we found that adding a term for accuracy on the Autobiographical Memory Task did not significantly improve model fit (`r print_model_comp(model_comp_AMT, "glmer5")`), suggesting that children's development of the concept of age may not be influenced by their ability to temporally order past memories.

To better understand the relationship between size cues and numerical age cues in children's age judgments, we explored how size congruence and numerical age condition interacted. We found that a Congruence * Condition interaction model improved model fit (`r print_model_comp(model_comp_int_congruence_condition, "int_model_congruence_condition")`) relative to a simpler model [Accuracy ~ Congruence + Condition + (1|PID) + (1|Item)]. Posthoc pairwise comparisons showed that while there was no significant difference in accuracy between the two conditions when the size difference between the figures was congruent (`r print_emm_contrast(congruence_condition_int, "Age / No Age", filter_level = "Congruent")`), children's age judgments were more accurate when they had access to numerical ages when the size difference was incongruent (`r print_emm_contrast(congruence_condition_int, "Age / No Age", filter_level = "Incongruent")`) and when the two figures were the same size (`r print_emm_contrast(congruence_condition_int, "Age / No Age", filter_level = "Same")`), suggesting that although children are influenced by size in their age judgments, this influence is reduced when they are able to make use of numerical age cues.
